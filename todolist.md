1. 对所有语言结构分析的精准度检测

## 测试状态

### 已完成测试文件
- ✅ Go: test-go.ts (已测试，生产环境验证)
- ✅ Python: test-python.ts
- ✅ TypeScript/JavaScript: test-typescript.ts
- ✅ Rust: test-rust.ts
- ✅ Java: test-java.ts
- ✅ HTML: test-html.ts

### 示例代码文件
- ✅ Go: sample-code.go
- ✅ Python: sample-code.py
- ✅ TypeScript: sample-code.ts
- ✅ Rust: sample-code.rs
- ✅ Java: sample-code.java
- ✅ HTML: sample-code.html

### 下一步
- 运行各语言的测试文件，验证 AST 解析精准度
- 检查符号提取、调用链、属性提取的准确性
- 根据测试结果优化 extractor 实现

---

2. 多模型构建支持

### 需求说明
支持为同一个代码库构建多个 embedding 模型和 summarizer 模型的索引，以便：
- 使用不同的 embedding 模型（不同维度、不同用途）
- 支持模型版本管理和迁移
- 支持不同场景选择不同模型（如：快速搜索用小模型，精准搜索用大模型）
- 支持多语言模型优化（不同语言使用最适合的模型）

### 实现方向
- [ ] 扩展配置格式，支持多模型配置数组
- [ ] 数据库结构支持多模型存储（每个 symbol 可对应多个 embedding 向量）
- [ ] Embedding 生成器支持批量生成多个模型的向量
- [ ] 查询引擎支持指定模型进行搜索
- [ ] 模型版本管理和迁移工具
- [ ] 性能优化：支持模型并行/串行生成策略

---

3. Token 使用量统计和成本计算

### 需求说明
在关键的构建步骤完成后输出 token 使用量统计，帮助用户计算 API 调用成本：
- 代码摘要生成（summarizer）的 token 统计
- Embedding 生成的 token 统计
- 按模型分别统计
- 支持成本估算（根据模型定价）

### 关键构建步骤
- **索引阶段**：AST 解析和符号提取（不消耗 token）
- **摘要生成阶段**：LLM 生成代码注释（消耗大量 token）
  - 输入 token：代码 + prompt
  - 输出 token：生成的摘要
- **Embedding 生成阶段**：向量化代码符号（消耗 token）
  - 输入 token：代码文本
  - 通常按 token 计费

### 实现方向
- [ ] 在 `ChunkSummarizer` 中汇总并输出 token 统计
  - 总输入 token 数
  - 总输出 token 数
  - 按模型分组统计
  - 成本估算（如果配置了模型定价）
- [ ] 在 `EmbeddingsGenerator` 中汇总并输出 token 统计
  - 总 token 数
  - 按模型分组统计
  - 成本估算
- [ ] CLI 命令输出格式优化
  - 摘要生成完成后显示统计信息
  - Embedding 生成完成后显示统计信息
  - 支持 JSON 格式输出（便于脚本处理）
- [ ] 数据库存储 token 使用记录
  - 记录每次构建的 token 使用量
  - 支持历史统计和成本分析
- [ ] 模型定价配置（可选）
  - 支持配置各模型的输入/输出 token 价格
  - 自动计算总成本
- [ ] 增量统计
  - 区分新增、更新、跳过（已存在）的 token 消耗
  - 帮助优化成本

---

4. DeepSeek-OCR 集成优化

### 评估结果
DeepSeek-OCR 通过"上下文光学压缩"技术，可将长文本转换为图像，大幅降低 token 消耗（10倍压缩比可达 97% 精度，20倍压缩比仍保持 60% 精度）。

### 高价值应用场景
- ✅ **代码摘要生成优化**（最高优先级）
  - 位置：`ChunkSummarizer.summarizeSymbol`
  - 场景：长代码块（>200行）消耗大量 token
  - 收益：10倍压缩可节省约 84% token 成本
  - 实现：超过阈值时使用 OCR 压缩 + 视觉模型生成摘要
- ✅ **批量摘要生成成本优化**
  - 场景：大型代码库（300+ 文件）
  - 收益：批量处理可显著降低总体成本

### 中等价值场景
- ⚠️ **超长代码块存储优化**：权衡存储空间 vs OCR 解码成本

### 低价值场景
- ❌ Embedding 生成：摘要通常较短，压缩收益有限
- ❌ 代码搜索：主要依赖结构化索引，不适用

### 实施计划
#### 阶段一：代码摘要生成优化（高优先级）
- [ ] 集成 DeepSeek-OCR 编码器
- [ ] 在 `ChunkSummarizer` 中添加代码长度检测（阈值：200-500行）
- [ ] 超过阈值时使用 OCR 压缩 + 视觉模型（GPT-4V/Claude 3.5）
- [ ] 添加压缩统计和成本对比报告
- [ ] 支持配置压缩阈值和压缩比
- **预期收益**：Token 成本降低 70-90%（针对长代码块）

#### 阶段二：批量处理优化（中优先级）
- [ ] 预处理阶段：扫描所有代码块，识别长代码块
- [ ] 批量压缩：使用 DeepSeek-OCR 批量编码
- [ ] 批量摘要：使用视觉模型批量处理
- [ ] 优化批量处理效率

#### 阶段三：存储优化（低优先级，需评估）
- [ ] 评估查询频率和存储成本
- [ ] 对于不常用查询的超长代码块，考虑压缩存储
- [ ] 权衡 OCR 解码成本 vs 存储节省

### 技术挑战
- [ ] 模型集成：集成 DeepSeek-OCR 编码器
- [ ] 视觉模型支持：支持视觉输入（GPT-4V, Claude 3.5 等）
- [ ] 精度权衡：20倍压缩时精度降至 60%，需要配置策略
- [ ] 性能开销：编码/解码需要额外时间，需要优化
- [ ] 配置管理：压缩阈值、压缩比等参数可配置

### 适用场景判断
- ✅ 代码库中有大量长函数（>200行）
- ✅ 摘要生成是主要成本来源
- ✅ 代码库规模大（>10万行）
- ❌ 代码库主要是短函数（<50行）- 不适用
- ❌ 小规模项目（<1万行）- 不适用

### 参考文档
详细评估报告：`docs/deepseek-ocr-evaluation.md`
